{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据集：伪造数据集（两个高斯分布混合）\n",
    "数据集长度：1000\n",
    "------------------------------\n",
    "运行结果：\n",
    "----------------------------\n",
    "the Parameters set is:\n",
    "alpha0:0.3, mu0:0.7, sigmod0:-2.0, alpha1:0.5, mu1:0.5, sigmod1:1.0\n",
    "----------------------------\n",
    "the Parameters predict is:\n",
    "alpha0:0.4, mu0:0.6, sigmod0:-1.7, alpha1:0.7, mu1:0.7, sigmod1:0.9\n",
    "----------------------------\n",
    "'''\n",
    "\n",
    "def loadData(mu0, sigma0, mu1, sigma1, alpha0, alpha1):\n",
    "    '''\n",
    "    初始化数据集\n",
    "    这里通过服从高斯分布的随机函数来伪造数据集\n",
    "    :param mu0: 高斯0的均值\n",
    "    :param sigma0: 高斯0的方差\n",
    "    :param mu1: 高斯1的均值\n",
    "    :param sigma1: 高斯1的方差\n",
    "    :param alpha0: 高斯0的系数\n",
    "    :param alpha1: 高斯1的系数\n",
    "    :return: 混合了两个高斯分布的数据\n",
    "    '''\n",
    "    # 定义数据集长度为1000\n",
    "    length = 1000\n",
    "\n",
    "    # 初始化第一个高斯分布，生成数据，数据长度为length * alpha系数，以此来\n",
    "    # 满足alpha的作用\n",
    "    data0 = np.random.normal(mu0, sigma0, int(length * alpha0))\n",
    "    # 第二个高斯分布的数据\n",
    "    data1 = np.random.normal(mu1, sigma1, int(length * alpha1))\n",
    "\n",
    "    # 初始化总数据集\n",
    "    # 两个高斯分布的数据混合后会放在该数据集中返回\n",
    "    dataSet = []\n",
    "    # 将第一个数据集的内容添加进去\n",
    "    dataSet.extend(data0)\n",
    "    # 添加第二个数据集的数据\n",
    "    dataSet.extend(data1)\n",
    "    # 对总的数据集进行打乱（其实不打乱也没事，只不过打乱一下直观上让人感觉已经混合了\n",
    "    # 读者可以将下面这句话屏蔽以后看看效果是否有差别）\n",
    "    random.shuffle(dataSet)\n",
    "\n",
    "    #返回伪造好的数据集\n",
    "    return dataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高斯分布公式，没有什么特殊的\n",
    "def calcGauss(dataSetArr, mu, sigmod):\n",
    "    '''\n",
    "    根据高斯密度函数计算值\n",
    "    依据：“9.3.1 高斯混合模型” 式9.25\n",
    "    注：在公式中y是一个实数，但是在EM算法中(见算法9.2的E步)，需要对每个j\n",
    "    都求一次yjk，在本实例中有1000个可观测数据，因此需要计算1000次。考虑到\n",
    "    在E步时进行1000次高斯计算，程序上比较不简洁，因此这里的y是向量，在numpy\n",
    "    的exp中如果exp内部值为向量，则对向量中每个值进行exp，输出仍是向量的形式。\n",
    "    所以使用向量的形式1次计算即可将所有计算结果得出，程序上较为简洁\n",
    "    \n",
    "    :param dataSetArr: 可观测数据集\n",
    "    :param mu: 均值\n",
    "    :param sigmod: 方差\n",
    "    :return: 整个可观测数据集的高斯分布密度（向量形式）\n",
    "    '''\n",
    "    # 计算过程就是依据式9.25写的，没有别的花样\n",
    "    result = (1 / (math.sqrt(2*math.pi)*sigmod**2)) * np.exp(-1 * (dataSetArr-mu) * (dataSetArr-mu) / (2*sigmod**2))\n",
    "    # 返回结果\n",
    "    return result\n",
    "\n",
    "\n",
    "def E_step(dataSetArr, alpha0, mu0, sigmod0, alpha1, mu1, sigmod1):\n",
    "    '''\n",
    "    EM算法中的E步\n",
    "    依据当前模型参数，计算分模型k对观数据y的响应度\n",
    "    :param dataSetArr: 可观测数据y\n",
    "    :param alpha0: 高斯模型0的系数\n",
    "    :param mu0: 高斯模型0的均值\n",
    "    :param sigmod0: 高斯模型0的方差\n",
    "    :param alpha1: 高斯模型1的系数\n",
    "    :param mu1: 高斯模型1的均值\n",
    "    :param sigmod1: 高斯模型1的方差\n",
    "    :return: 两个模型各自的响应度\n",
    "    '''\n",
    "    # 计算y0的响应度\n",
    "    # 先计算模型0的响应度的分子\n",
    "    gamma0 = alpha0 * calcGauss(dataSetArr, mu0, sigmod0)\n",
    "    #print(\"gamma0=\",gamma0.shape) # 1000, 维向量\n",
    "    # 模型1响应度的分子\n",
    "    gamma1 = alpha1 * calcGauss(dataSetArr, mu1, sigmod1)\n",
    "\n",
    "    # 两者相加为E步中的分布\n",
    "    sum = gamma0 + gamma1\n",
    "    # 各自相除，得到两个模型的响应度\n",
    "    gamma0 = gamma0 / sum\n",
    "    gamma1 = gamma1 / sum\n",
    "\n",
    "    # 返回两个模型响应度\n",
    "    return gamma0, gamma1\n",
    "\n",
    "def M_step(muo, mu1, gamma0, gamma1, dataSetArr):\n",
    "    # 依据算法9.2计算各个值\n",
    "    # 这里没什么花样，对照书本公式看看这里就好了\n",
    "    \n",
    "    # np.dot 点积：[1,2] [2,3] = [2,6]\n",
    "    mu0_new = np.dot(gamma0, dataSetArr) / np.sum(gamma0)\n",
    "    mu1_new = np.dot(gamma1, dataSetArr) / np.sum(gamma1)\n",
    "\n",
    "    # math.sqrt  平方根 \n",
    "    sigmod0_new = math.sqrt(np.dot(gamma0, (dataSetArr - muo)**2) / np.sum(gamma0))\n",
    "    sigmod1_new = math.sqrt(np.dot(gamma1, (dataSetArr - mu1)**2) / np.sum(gamma1))\n",
    "\n",
    "    alpha0_new = np.sum(gamma0) / len(gamma0)\n",
    "    alpha1_new = np.sum(gamma1) / len(gamma1)\n",
    "\n",
    "    # 将更新的值返回\n",
    "    return mu0_new, mu1_new, sigmod0_new, sigmod1_new, alpha0_new, alpha1_new\n",
    "\n",
    "\n",
    "## 训练主函数\n",
    "def EM_Train(dataSetList, iter=500):\n",
    "    '''\n",
    "    根据EM算法进行参数估计\n",
    "    算法依据“9.3.2 高斯混合模型参数估计的EM算法” 算法9.2\n",
    "    :param dataSetList:数据集（可观测数据）\n",
    "    :param iter: 迭代次数\n",
    "    :return: 估计的参数\n",
    "    '''\n",
    "    # 将可观测数据y转换为数组形式，主要是为了方便后续运算\n",
    "    dataSetArr = np.array(dataSetList)\n",
    "\n",
    "    # 步骤1：对参数取初值，开始迭代\n",
    "    alpha0 = 0.5\n",
    "    mu0 = 0\n",
    "    sigmod0 = 1\n",
    "    alpha1 = 0.5\n",
    "    mu1 = 1\n",
    "    sigmod1 = 1\n",
    "\n",
    "    # 开始迭代\n",
    "    step = 0\n",
    "    while (step < iter):\n",
    "        # 每次进入一次迭代后迭代次数加1\n",
    "        step += 1\n",
    "        # 步骤2：E步：依据当前模型参数，计算分模型k对观测数据y的响应度\n",
    "        gamma0, gamma1 = E_step(dataSetArr, alpha0, mu0, sigmod0, alpha1, mu1, sigmod1)\n",
    "        # 步骤3：M步\n",
    "        mu0, mu1, sigmod0, sigmod1, alpha0, alpha1 = M_step(mu0, mu1, gamma0, gamma1, dataSetArr)\n",
    "\n",
    "    # 迭代结束后将更新后的各参数返回\n",
    "    return alpha0, mu0, sigmod0, alpha1, mu1, sigmod1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "\n",
    "    # 设置两个高斯模型进行混合，这里是初始化两个模型各自的参数\n",
    "    # 见“9.3 EM算法在高斯混合模型学习中的应用”\n",
    "    # alpha是“9.3.1 高斯混合模型” 定义9.2中的系数α\n",
    "    # mu0是均值μ\n",
    "    # sigmod是方差σ\n",
    "    # 在设置上两个alpha的和必须为1，其他没有什么具体要求，符合高斯定义就可以\n",
    "    \n",
    "    alpha0 = 0.3  # 系数α\n",
    "    mu0 = -2  # 均值μ\n",
    "    sigmod0 = 0.5  # 方差σ\n",
    "\n",
    "    alpha1 = 0.7  # 系数α\n",
    "    mu1 = 0.5  # 均值μ\n",
    "    sigmod1 = 1  # 方差σ\n",
    "\n",
    "    # 初始化数据集\n",
    "    dataSetList = loadData(mu0, sigmod0, mu1, sigmod1, alpha0, alpha1)\n",
    "\n",
    "    #打印设置的参数\n",
    "    print('---------------------------')\n",
    "    print('the Parameters set is:')\n",
    "    print('alpha0:%.1f, mu0:%.1f, sigmod0:%.1f, alpha1:%.1f, mu1:%.1f, sigmod1:%.1f' % (\n",
    "        alpha0, alpha1, mu0, mu1, sigmod0, sigmod1\n",
    "    ))\n",
    "\n",
    "    # 开始EM算法，进行参数估计\n",
    "    alpha0, mu0, sigmod0, alpha1, mu1, sigmod1 = EM_Train(dataSetList)\n",
    "\n",
    "    # 打印参数预测结果\n",
    "    print('----------------------------')\n",
    "    print('the Parameters predict is:')\n",
    "    print('alpha0:%.1f, mu0:%.1f, sigmod0:%.1f, alpha1:%.1f, mu1:%.1f, sigmod1:%.1f' % (\n",
    "        alpha0, alpha1, mu0, mu1, sigmod0, sigmod1\n",
    "    ))\n",
    "\n",
    "    # 打印时间\n",
    "    print('----------------------------')\n",
    "    print('time span:', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M步计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    " \n",
    "#生成随机数据，4个高斯模型\n",
    "def generate_data(sigma,N,mu1,mu2,mu3,mu4,alpha):\n",
    "    global X                  #可观测数据集\n",
    "    X = np.zeros((N, 2))       # 初始化X，2行N列。2维数据，N个样本\n",
    "    X=np.matrix(X)\n",
    "    global mu                 #随机初始化mu1，mu2，mu3，mu4\n",
    "    mu = np.random.random((4,2))\n",
    "    mu=np.matrix(mu)\n",
    "    global excep              #期望第i个样本属于第j个模型的概率的期望\n",
    "    excep=np.zeros((N,4))\n",
    "    global alpha_             #初始化混合项系数\n",
    "    alpha_=[0.25,0.25,0.25,0.25]\n",
    "    for i in range(N):\n",
    "        if np.random.random(1) < 0.1:  # 生成0-1之间随机数\n",
    "            X[i,:]  = np.random.multivariate_normal(mu1, sigma, 1)     #用第一个高斯模型生成2维数据\n",
    "        elif 0.1 <= np.random.random(1) < 0.3:\n",
    "            X[i,:] = np.random.multivariate_normal(mu2, sigma, 1)      #用第二个高斯模型生成2维数据\n",
    "        elif 0.3 <= np.random.random(1) < 0.6:\n",
    "            X[i,:] = np.random.multivariate_normal(mu3, sigma, 1)      #用第三个高斯模型生成2维数据\n",
    "        else:\n",
    "            X[i,:] = np.random.multivariate_normal(mu4, sigma, 1)      #用第四个高斯模型生成2维数据\n",
    " \n",
    "    print(\"可观测数据：\\n\",X)       #输出可观测样本\n",
    "    print(\"初始化的mu1，mu2，mu3，mu4：\",mu)      #输出初始化的mu\n",
    "\n",
    "\n",
    "# E 期望\n",
    "#  \\hat{\\gamma_{jk}}\n",
    "def e_step(sigma,k,N):\n",
    "    global X\n",
    "    global mu\n",
    "    global excep\n",
    "    global alpha_\n",
    "    for i in range(N):\n",
    "        denom=0\n",
    "        for j in range(0,k):\n",
    "            #  sigma.I 表示矩阵的逆矩阵\n",
    "            # np.transpose ：矩阵转置   np.linalg.det():矩阵求行列式\n",
    "            denom += alpha_[j]*  math.exp(-(X[i,:]-mu[j,:])*sigma.I*np.transpose(X[i,:]-mu[j,:]))  /np.sqrt(np.linalg.det(sigma))       #分母\n",
    "        for j in range(0,k):\n",
    "            numer = math.exp(-(X[i,:]-mu[j,:])*sigma.I*np.transpose(X[i,:]-mu[j,:]))/np.sqrt(np.linalg.det(sigma))        #分子\n",
    "            excep[i,j]=alpha_[j]*numer/denom      #求期望\n",
    "    print(\"隐藏变量：\\n\",excep)\n",
    "\n",
    "    \n",
    "def m_step(k,N):\n",
    "    global excep\n",
    "    global X\n",
    "    global alpha_\n",
    "    for j in range(0,k):\n",
    "        denom=0   #分母\n",
    "        numer=0   #分子\n",
    "        for i in range(N):\n",
    "            numer += excep[i,j]*X[i,:]\n",
    "            denom += excep[i,j]\n",
    "        mu[j,:] = numer/denom    #求均值\n",
    "        alpha_[j]=denom/N        #求混合项系数\n",
    "\n",
    "        #     #可视化结果\n",
    "def plotShow():\n",
    "    # 画生成的原始数据\n",
    "    plt.subplot(221)\n",
    "    plt.scatter(X[:,0].tolist(), X[:,1].tolist(),c='b',s=25,alpha=0.4,marker='o')    #T散点颜色，s散点大小，alpha透明度，marker散点形状\n",
    "    plt.title('random generated data')\n",
    "    #画分类好的数据\n",
    "    plt.subplot(222)\n",
    "    plt.title('classified data through EM')\n",
    "    order=np.zeros(N)\n",
    "    color=['b','r','k','y']\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            if excep[i,j]==max(excep[i,:]):\n",
    "                order[i]=j     #选出X[i,:]属于第几个高斯模型\n",
    "            probility[i] += alpha_[int(order[i])]*math.exp(-(X[i,:]-mu[j,:])*sigma.I*np.transpose(X[i,:]-mu[j,:]))/(np.sqrt(np.linalg.det(sigma))*2*np.pi)    #计算混合高斯分布\n",
    "        plt.scatter(X[i, 0], X[i, 1], c=color[int(order[i])], s=25, alpha=0.4, marker='o')      #绘制分类后的散点图\n",
    "    #绘制三维图像\n",
    "    ax = plt.subplot(223, projection='3d')\n",
    "    plt.title('3d view')\n",
    "    for i in range(N):\n",
    "        ax.scatter(X[i, 0], X[i, 1], probility[i], c=color[int(order[i])])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    iter_num=1000  #迭代次数\n",
    "    N=500         #样本数目\n",
    "    k=4            #高斯模型数\n",
    "    probility = np.zeros(N)    #混合高斯分布\n",
    "    u1=[5,35]\n",
    "    u2=[30,40]\n",
    "    u3=[20,20]\n",
    "    u4=[45,15]\n",
    "    sigma=np.matrix([[30, 0], [0, 30]])               #协方差矩阵\n",
    "    alpha=[0.1,0.2,0.3,0.4]         #混合项系数\n",
    "    generate_data(sigma,N,u1,u2,u3,u4,alpha)     #生成数据\n",
    "    #迭代计算\n",
    "    for i in range(iter_num):\n",
    "        err=0     #均值误差\n",
    "        err_alpha=0    #混合项系数误差\n",
    "        Old_mu = copy.deepcopy(mu)\n",
    "        Old_alpha = copy.deepcopy(alpha_)\n",
    "        \n",
    "        e_step(sigma,k,N)     # E步\n",
    "        m_step(k,N)           # M步\n",
    "        \n",
    "        print(\"迭代次数:\",i+1)\n",
    "        print(\"估计的均值:\",mu)\n",
    "        print(\"估计的混合项系数:\",alpha_)\n",
    "        for z in range(k):\n",
    "            err += (abs(Old_mu[z,0]-mu[z,0])+abs(Old_mu[z,1]-mu[z,1]))      #计算误差\n",
    "            err_alpha += abs(Old_alpha[z]-alpha_[z])\n",
    "        if (err<=0.001) and (err_alpha<0.001):     #达到精度退出迭代\n",
    "            print(err,err_alpha)\n",
    "            break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图\n",
    "plotShow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
